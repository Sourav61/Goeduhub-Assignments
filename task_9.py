# -*- coding: utf-8 -*-
"""Task-9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Sourav61/Goeduhub-Assignments/blob/main/Task_09.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

"""Author: <a href = "https://github.com/Sourav61">Sourav Pahwa</a>
<br>ID: GO_STP_13420

<b>Q) Predict retention of an employee within an organization such that whether the employee will leave the company or continue with it. An organization is only as good as its employees, and these people are the true source of its competitive advantage. Dataset is downloaded from Kaggle. Link: <a href="https://www.kaggle.com/giripujar/hr-analytics">https://www.kaggle.com/giripujar/hr-analytics")</a></b>

First do data exploration and visualization, after this create a logistic regression model to predict Employee Attrition Using Machine Learning & Python.
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as msno
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("HR_comma_sep.csv")

df.head(10)

df.tail(10)

df.info()

df.describe(include="all")

df.kurt()

df.skew()

df.keys()

df.columns

df.axes

df.items()

df.boxplot(rot=45)
plt.show()

df.hist(figsize=(15,20),xrot=45,yrot=45)
plt.show()

df.dtypes

df.duplicated().any()

df.duplicated().sum()

df.isna()

df.isnull().any()

df.isnull().sum()

msno.bar(df.sample(14999),color="cyan")
plt.show()

msno.matrix(df.sample(14999),color=(1, 0, 1))
plt.show()

df.corr()

fig = plt.figure(figsize = (12,10))
sns.heatmap(df.corr(), cmap='inferno', annot = True) 
plt.show()

corr = df.corr()
sns.heatmap((corr),
xticklabels=corr.columns.values,
yticklabels=corr.columns.values,cmap='cubehelix_r',annot=False,fmt=".2g")
plt.title('Heatmap of Correlation Matrix', fontsize=20)
corr

plt.figure(figsize=(14,14))
sns.heatmap(df.cov(), annot=True, fmt =".2f",square=True,cmap='rainbow')
plt.title("Covariation",fontsize = 15)
plt.show()

satisfaction_mean = df['satisfaction_level'].mean()
left_mean = df[df['left']==1]['satisfaction_level'].mean()
print( f'The mean for the employee population is: {satisfaction_mean}')
print( f'The mean for the employees that had left is: {left_mean}')

f, axes = plt.subplots(ncols=3, figsize=(15, 6))
sns.distplot(df.satisfaction_level, kde=False, color="m", ax=axes[0]).set_title('Employee Satisfaction Measure',fontsize=14)
axes[0].set_ylabel('Employee Count',fontsize=10)
sns.distplot(df.last_evaluation, kde=False, color="g", ax=axes[1]).set_title('Employee Evaluation Measure',fontsize=14)
axes[1].set_ylabel('Employee Count',fontsize=10)
sns.distplot(df.average_montly_hours, kde=False, color="b", ax=axes[2]).set_title('Employee Average Monthly Hours Measure',fontsize=14)
axes[2].set_ylabel('Employee Count',fontsize=10)
plt.show()

f, ax = plt.subplots(figsize=(15, 4))
sns.countplot(y="salary", hue='left', data=df).set_title('Employee Salary Turnover Distribution');

color_types = ['#78C850','#F08030','#6890F0','#A8B820','#A8A878','#A040A0','#F8D030',
'#E0C068','#EE99AC','#C03028','#F85888','#B8A038','#705898','#98D8D8','#7038F8']
sns.countplot(x='Department', data=df, palette=color_types).set_title('Employee Department Distribution');

data = df[['satisfaction_level','average_montly_hours','promotion_last_5years','salary']]
data.head(10)

df1 = pd.get_dummies(data['salary'])
df1.head(10)

df1.tail(10)

merge = pd.concat([data,df1],axis='columns')
merge

merge.drop(['salary','high'], axis=1, inplace=True)
merge

x = merge.copy()
x

y = df['left']
y

from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=.25, random_state=5)
print(xtrain.shape) 
print(xtest.shape)
print(ytrain.shape)
ytest.shape

from sklearn.linear_model import LogisticRegression
lm = LogisticRegression(solver='newton-cg')
lm.fit(xtrain,ytrain)

y_pred = lm.predict(xtest)
y_pred

lm.score(xtest,ytest)

from sklearn.metrics import accuracy_score, confusion_matrix,plot_confusion_matrix,mean_squared_error, mean_absolute_error ,r2_score,  classification_report

accuracy_score(ytest,y_pred)

confusion_matrix(ytest,y_pred)

plot_confusion_matrix(lm, xtest, ytest,cmap=plt.cm.cubehelix_r)
plt.show()

print("The Mean Squared Error is: ", end=" ")
mse = mean_squared_error(y_pred,ytest)
print(mse)
print("The Mean Absolute Error is: ", end=" ")
mae = mean_absolute_error(y_pred, ytest)
print(mae)

print('The R2 Score is: %0.2f ' % r2_score(ytest, y_pred))

print(classification_report(ytest,y_pred))

plt.scatter(ytest, y_pred,c='m', marker="^")
plt.plot(ytest, lm.predict(xtest))
plt.show()